{
  "hash": "f6c993aaee2d7142c01ad234aefd8828",
  "result": {
    "markdown": "---\ntitle: \"multivariate\"\nexecute: \n  echo: true\nformat: revealjs\neditor: visual\n---\n\n\n## Multiple DVs\n\n- Normally we are only interested in 1 DV at a time. However, many theories incorprate multiple DVs. With longitudinal models it is easy to incorporate multivariate questions. \n\n- SEM is well suited for multiple DVs as there is less of an emphasis on a single traidtional equation. \"If you can draw it you can model it\" \n\n- Some ~basic multivariate models can be run with MLM\n\n## Growth models x2\n\nWhat does a multivariate growth model look like? \n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\naffect <- read.csv(\"https://raw.githubusercontent.com/josh-jackson/longitudinal-2022/main/longitudinal.csv\")\nlibrary(lavaan)\nlibrary(tidyverse)\n\n\n\nmodel.1 <- '  i =~ 1*PosAFF11 + 1*PosAFF12 + 1*PosAFF13 \n            s =~ 0*PosAFF11 + 1*PosAFF12 + 2*PosAFF13'\n\nfit.1 <- growth(model.1, data=affect)\nsummary(fit.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nlavaan 0.6-11 ended normally after 31 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         8\n                                                      \n  Number of observations                           368\n                                                      \nModel Test User Model:\n                                                      \n  Test statistic                                 0.016\n  Degrees of freedom                                 1\n  P-value (Chi-square)                           0.898\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  i =~                                                \n    PosAFF11          1.000                           \n    PosAFF12          1.000                           \n    PosAFF13          1.000                           \n  s =~                                                \n    PosAFF11          0.000                           \n    PosAFF12          1.000                           \n    PosAFF13          2.000                           \n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  i ~~                                                \n    s                -0.041    0.026   -1.609    0.108\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .PosAFF11          0.000                           \n   .PosAFF12          0.000                           \n   .PosAFF13          0.000                           \n    i                 3.210    0.035   91.085    0.000\n    s                 0.045    0.020    2.268    0.023\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .PosAFF11          0.314    0.049    6.456    0.000\n   .PosAFF12          0.244    0.024   10.322    0.000\n   .PosAFF13          0.185    0.038    4.930    0.000\n    i                 0.210    0.046    4.608    0.000\n    s                 0.024    0.021    1.187    0.235\n```\n:::\n:::\n\n\n\n\n-----\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nmodel.2 <- '  i1 =~ 1*PosAFF11 + 1*PosAFF12 + 1*PosAFF13 \n            s1 =~ 0*PosAFF11 + 1*PosAFF12 + 2*PosAFF13\n            \n             i2 =~ 1*NegAFF21 + 1*NegAFF22 + 1*NegAFF23 \n            s2 =~ 0*NegAFF21 + 1*NegAFF22 + 2*NegAFF23\n\n'\n\nfit.2 <- growth(model.2, data=affect, missing = \"ML\")\nsummary(fit.2, standardized = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nlavaan 0.6-11 ended normally after 67 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        20\n                                                      \n  Number of observations                           368\n  Number of missing patterns                         1\n                                                      \nModel Test User Model:\n                                                      \n  Test statistic                                64.081\n  Degrees of freedom                                 7\n  P-value (Chi-square)                           0.000\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Observed\n  Observed information based on                Hessian\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  i1 =~                                                                 \n    PosAFF11          1.000                               0.443    0.605\n    PosAFF12          1.000                               0.443    0.716\n    PosAFF13          1.000                               0.443    0.766\n  s1 =~                                                                 \n    PosAFF11          0.000                               0.000    0.000\n    PosAFF12          1.000                               0.116    0.188\n    PosAFF13          2.000                               0.232    0.402\n  i2 =~                                                                 \n    NegAFF21          1.000                               0.397    0.690\n    NegAFF22          1.000                               0.397    0.940\n    NegAFF23          1.000                               0.397    0.987\n  s2 =~                                                                 \n    NegAFF21          0.000                               0.000    0.000\n    NegAFF22          1.000                               0.109    0.258\n    NegAFF23          2.000                               0.218    0.543\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  i1 ~~                                                                 \n    s1               -0.030    0.025   -1.208    0.227   -0.586   -0.586\n    i2               -0.128    0.020   -6.412    0.000   -0.727   -0.727\n    s2                0.040    0.010    3.965    0.000    0.837    0.837\n  s1 ~~                                                                 \n    i2                0.047    0.011    4.276    0.000    1.009    1.009\n    s2               -0.024    0.006   -4.154    0.000   -1.893   -1.893\n  i2 ~~                                                                 \n    s2               -0.037    0.013   -2.815    0.005   -0.863   -0.863\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .PosAFF11          0.000                               0.000    0.000\n   .PosAFF12          0.000                               0.000    0.000\n   .PosAFF13          0.000                               0.000    0.000\n   .NegAFF21          0.000                               0.000    0.000\n   .NegAFF22          0.000                               0.000    0.000\n   .NegAFF23          0.000                               0.000    0.000\n    i1                3.210    0.035   91.035    0.000    7.252    7.252\n    s1                0.045    0.020    2.269    0.023    0.390    0.390\n    i2                1.389    0.028   50.166    0.000    3.499    3.499\n    s2               -0.057    0.015   -3.837    0.000   -0.518   -0.518\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .PosAFF11          0.340    0.048    7.134    0.000    0.340    0.634\n   .PosAFF12          0.233    0.022   10.351    0.000    0.233    0.609\n   .PosAFF13          0.205    0.038    5.453    0.000    0.205    0.612\n   .NegAFF21          0.173    0.024    7.172    0.000    0.173    0.523\n   .NegAFF22          0.083    0.009    8.963    0.000    0.083    0.468\n   .NegAFF23          0.106    0.017    6.262    0.000    0.106    0.655\n    i1                0.196    0.044    4.463    0.000    1.000    1.000\n    s1                0.013    0.020    0.660    0.509    1.000    1.000\n    i2                0.157    0.024    6.518    0.000    1.000    1.000\n    s2                0.012    0.010    1.164    0.245    1.000    1.000\n```\n:::\n:::\n\n\n\n## second order\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmv.sec.order <- '\n## define latent variables\nPos1 =~ NA*PosAFF11 + L1*PosAFF11 + L2*PosAFF21 + L3*PosAFF31\nPos2 =~ NA*PosAFF12 + L1*PosAFF12 + L2*PosAFF22 + L3*PosAFF32\nPos3 =~ NA*PosAFF13 + L1*PosAFF13 + L2*PosAFF23 + L3*PosAFF33\n\nNeg1 =~ NA*NegAFF11 + L4*NegAFF11 + L5*NegAFF21 + L6*NegAFF31\nNeg2 =~ NA*NegAFF12 + L4*NegAFF12 + L5*NegAFF22 + L6*NegAFF32\nNeg3 =~ NA*NegAFF13 + L4*NegAFF13 + L5*NegAFF23 + L6*NegAFF33\n\n## intercepts\nPosAFF11 ~ t1*1\nPosAFF21 ~ t2*1\nPosAFF31 ~ t3*1\n\nPosAFF12 ~ t1*1\nPosAFF22 ~ t2*1\nPosAFF32 ~ t3*1\n\nPosAFF13 ~ t1*1\nPosAFF23 ~ t2*1\nPosAFF33 ~ t3*1\n\nNegAFF11 ~ tt1*1\nNegAFF21 ~ tt2*1\nNegAFF31 ~ tt3*1\n\nNegAFF12 ~ tt1*1\nNegAFF22 ~ tt2*1\nNegAFF32 ~ tt3*1\n\nNegAFF13 ~ tt1*1\nNegAFF23 ~ tt2*1\nNegAFF33 ~ tt3*1\n\n\n## correlated residuals across time\nPosAFF11 ~~ PosAFF12 + PosAFF13\nPosAFF12 ~~ PosAFF13\nPosAFF21 ~~ PosAFF22 + PosAFF23\nPosAFF22 ~~ PosAFF23\nPosAFF31 ~~ PosAFF32 + PosAFF33\nPosAFF32 ~~ PosAFF33\n\nNegAFF11 ~~ NegAFF12 + NegAFF13\nNegAFF12 ~~ NegAFF13\nNegAFF21 ~~ NegAFF22 + NegAFF23\nNegAFF22 ~~ NegAFF23\nNegAFF31 ~~ NegAFF32 + NegAFF33\nNegAFF32 ~~ NegAFF33\n\n## latent variable intercepts\nPos1 ~ 0*1\nPos2  ~ 0*1\nPos3  ~ 0*1\n\nNeg1 ~ 0*1\nNeg2  ~ 0*1\nNeg3  ~ 0*1\n\n#model constraints for effect coding\n## loadings must average to 1\nL1 == 3 - L2 - L3\nL4 == 3 - L5 - L6\n## means must average to 0\nt1 == 0 - t2 - t3\ntt1 == 0 - tt2 - tt3\n\ni.p =~ 1*Pos1 + 1*Pos2 + 1*Pos3 \ns.p =~ 0*Pos1 + 1*Pos2 + 2*Pos3\n\ni.n =~ 1*Neg1 + 1*Neg2 + 1*Neg3 \ns.n =~ 0*Neg1 + 1*Neg2 + 2*Neg3'\n\n\nmv.secondorder <- growth(mv.sec.order, data=affect, missing = \"ML\")\n```\n:::\n\n\n\n-------\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(mv.secondorder, standardized = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nlavaan 0.6-11 ended normally after 191 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        92\n  Number of equality constraints                    28\n                                                      \n  Number of observations                           368\n  Number of missing patterns                         1\n                                                      \nModel Test User Model:\n                                                      \n  Test statistic                               248.244\n  Degrees of freedom                               125\n  P-value (Chi-square)                           0.000\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Observed\n  Observed information based on                Hessian\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  Pos1 =~                                                               \n    PosAFF11  (L1)    0.948    0.014   68.484    0.000    0.640    0.894\n    PosAFF21  (L2)    1.015    0.015   68.707    0.000    0.686    0.886\n    PosAFF31  (L3)    1.037    0.014   73.770    0.000    0.701    0.918\n  Pos2 =~                                                               \n    PosAFF12  (L1)    0.948    0.014   68.484    0.000    0.564    0.887\n    PosAFF22  (L2)    1.015    0.015   68.707    0.000    0.605    0.878\n    PosAFF32  (L3)    1.037    0.014   73.770    0.000    0.618    0.931\n  Pos3 =~                                                               \n    PosAFF13  (L1)    0.948    0.014   68.484    0.000    0.509    0.883\n    PosAFF23  (L2)    1.015    0.015   68.707    0.000    0.545    0.864\n    PosAFF33  (L3)    1.037    0.014   73.770    0.000    0.557    0.890\n  Neg1 =~                                                               \n    NegAFF11  (L4)    1.029    0.018   58.212    0.000    0.552    0.862\n    NegAFF21  (L5)    0.959    0.017   55.123    0.000    0.515    0.868\n    NegAFF31  (L6)    1.011    0.016   62.776    0.000    0.543    0.911\n  Neg2 =~                                                               \n    NegAFF12  (L4)    1.029    0.018   58.212    0.000    0.377    0.838\n    NegAFF22  (L5)    0.959    0.017   55.123    0.000    0.351    0.865\n    NegAFF32  (L6)    1.011    0.016   62.776    0.000    0.370    0.901\n  Neg3 =~                                                               \n    NegAFF13  (L4)    1.029    0.018   58.212    0.000    0.363    0.780\n    NegAFF23  (L5)    0.959    0.017   55.123    0.000    0.338    0.847\n    NegAFF33  (L6)    1.011    0.016   62.776    0.000    0.357    0.883\n  i.p =~                                                                \n    Pos1              1.000                               0.699    0.699\n    Pos2              1.000                               0.793    0.793\n    Pos3              1.000                               0.880    0.880\n  s.p =~                                                                \n    Pos1              0.000                               0.000    0.000\n    Pos2              1.000                               0.188    0.188\n    Pos3              2.000                               0.418    0.418\n  i.n =~                                                                \n    Neg1              1.000                               0.697    0.697\n    Neg2              1.000                               1.021    1.021\n    Neg3              1.000                               1.059    1.059\n  s.n =~                                                                \n    Neg1              0.000                               0.000    0.000\n    Neg2              1.000                               0.279    0.279\n    Neg3              2.000                               0.578    0.578\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n .PosAFF11 ~~                                                           \n   .PosAFF12          0.004    0.007    0.581    0.561    0.004    0.043\n   .PosAFF13         -0.001    0.007   -0.091    0.927   -0.001   -0.007\n .PosAFF12 ~~                                                           \n   .PosAFF13          0.002    0.006    0.324    0.746    0.002    0.024\n .PosAFF21 ~~                                                           \n   .PosAFF22          0.008    0.008    0.969    0.333    0.008    0.069\n   .PosAFF23          0.006    0.008    0.772    0.440    0.006    0.056\n .PosAFF22 ~~                                                           \n   .PosAFF23          0.012    0.007    1.608    0.108    0.012    0.114\n .PosAFF31 ~~                                                           \n   .PosAFF32          0.005    0.007    0.768    0.443    0.005    0.072\n   .PosAFF33          0.016    0.007    2.126    0.034    0.016    0.181\n .PosAFF32 ~~                                                           \n   .PosAFF33          0.004    0.006    0.695    0.487    0.004    0.062\n .NegAFF11 ~~                                                           \n   .NegAFF12          0.006    0.006    1.048    0.294    0.006    0.073\n   .NegAFF13          0.006    0.006    0.998    0.318    0.006    0.067\n .NegAFF12 ~~                                                           \n   .NegAFF13          0.007    0.005    1.492    0.136    0.007    0.099\n .NegAFF21 ~~                                                           \n   .NegAFF22          0.015    0.004    3.263    0.001    0.015    0.244\n   .NegAFF23          0.010    0.005    2.168    0.030    0.010    0.163\n .NegAFF22 ~~                                                           \n   .NegAFF23          0.011    0.003    3.235    0.001    0.011    0.250\n .NegAFF31 ~~                                                           \n   .NegAFF32         -0.006    0.004   -1.577    0.115   -0.006   -0.145\n   .NegAFF33         -0.008    0.004   -1.793    0.073   -0.008   -0.166\n .NegAFF32 ~~                                                           \n   .NegAFF33         -0.002    0.003   -0.674    0.500   -0.002   -0.062\n  i.p ~~                                                                \n    s.p              -0.036    0.022   -1.581    0.114   -0.671   -0.671\n    i.n              -0.151    0.019   -7.794    0.000   -0.853   -0.853\n    s.n               0.054    0.010    5.454    0.000    1.129    1.129\n  s.p ~~                                                                \n    i.n               0.063    0.010    6.314    0.000    1.493    1.493\n    s.n              -0.036    0.005   -6.625    0.000   -3.133   -3.133\n  i.n ~~                                                                \n    s.n              -0.035    0.012   -2.880    0.004   -0.923   -0.923\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .PosAFF11  (t1)    0.216    0.045    4.791    0.000    0.216    0.302\n   .PosAFF21  (t2)   -0.154    0.048   -3.187    0.001   -0.154   -0.198\n   .PosAFF31  (t3)   -0.063    0.046   -1.365    0.172   -0.063   -0.082\n   .PosAFF12  (t1)    0.216    0.045    4.791    0.000    0.216    0.340\n   .PosAFF22  (t2)   -0.154    0.048   -3.187    0.001   -0.154   -0.223\n   .PosAFF32  (t3)   -0.063    0.046   -1.365    0.172   -0.063   -0.094\n   .PosAFF13  (t1)    0.216    0.045    4.791    0.000    0.216    0.375\n   .PosAFF23  (t2)   -0.154    0.048   -3.187    0.001   -0.154   -0.244\n   .PosAFF33  (t3)   -0.063    0.046   -1.365    0.172   -0.063   -0.100\n   .NegAFF11 (tt1)    0.039    0.025    1.553    0.120    0.039    0.061\n   .NegAFF21 (tt2)    0.018    0.025    0.716    0.474    0.018    0.030\n   .NegAFF31 (tt3)   -0.056    0.023   -2.497    0.013   -0.056   -0.095\n   .NegAFF12 (tt1)    0.039    0.025    1.553    0.120    0.039    0.087\n   .NegAFF22 (tt2)    0.018    0.025    0.716    0.474    0.018    0.043\n   .NegAFF32 (tt3)   -0.056    0.023   -2.497    0.013   -0.056   -0.137\n   .NegAFF13 (tt1)    0.039    0.025    1.553    0.120    0.039    0.084\n   .NegAFF23 (tt2)    0.018    0.025    0.716    0.474    0.018    0.044\n   .NegAFF33 (tt3)   -0.056    0.023   -2.497    0.013   -0.056   -0.140\n   .Pos1              0.000                               0.000    0.000\n   .Pos2              0.000                               0.000    0.000\n   .Pos3              0.000                               0.000    0.000\n   .Neg1              0.000                               0.000    0.000\n   .Neg2              0.000                               0.000    0.000\n   .Neg3              0.000                               0.000    0.000\n    i.p               3.193    0.035   92.501    0.000    6.758    6.758\n    s.p               0.018    0.018    0.996    0.319    0.163    0.163\n    i.n               1.414    0.027   52.911    0.000    3.781    3.781\n    s.n              -0.047    0.015   -3.271    0.001   -0.465   -0.465\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .PosAFF11          0.103    0.011    9.281    0.000    0.103    0.201\n   .PosAFF21          0.129    0.013    9.683    0.000    0.129    0.215\n   .PosAFF31          0.092    0.012    7.837    0.000    0.092    0.157\n   .PosAFF12          0.086    0.009    9.582    0.000    0.086    0.213\n   .PosAFF22          0.109    0.011   10.042    0.000    0.109    0.229\n   .PosAFF32          0.059    0.009    6.869    0.000    0.059    0.134\n   .PosAFF13          0.073    0.008    8.877    0.000    0.073    0.221\n   .PosAFF23          0.101    0.010    9.715    0.000    0.101    0.254\n   .PosAFF33          0.081    0.009    8.640    0.000    0.081    0.208\n   .NegAFF11          0.105    0.011   10.019    0.000    0.105    0.257\n   .NegAFF21          0.086    0.009    9.635    0.000    0.086    0.246\n   .NegAFF31          0.061    0.008    7.271    0.000    0.061    0.171\n   .NegAFF12          0.060    0.006   10.358    0.000    0.060    0.298\n   .NegAFF22          0.042    0.005    9.127    0.000    0.042    0.252\n   .NegAFF32          0.032    0.004    7.515    0.000    0.032    0.188\n   .NegAFF13          0.085    0.008   10.966    0.000    0.085    0.392\n   .NegAFF23          0.045    0.005    8.959    0.000    0.045    0.283\n   .NegAFF33          0.036    0.005    7.399    0.000    0.036    0.221\n   .Pos1              0.234    0.041    5.641    0.000    0.511    0.511\n   .Pos2              0.190    0.021    9.025    0.000    0.536    0.536\n   .Pos3              0.157    0.034    4.600    0.000    0.545    0.545\n   .Neg1              0.148    0.022    6.683    0.000    0.515    0.515\n   .Neg2              0.054    0.008    6.944    0.000    0.405    0.405\n   .Neg3              0.084    0.015    5.626    0.000    0.674    0.674\n    i.p               0.223    0.041    5.464    0.000    1.000    1.000\n    s.p               0.013    0.018    0.686    0.493    1.000    1.000\n    i.n               0.140    0.022    6.382    0.000    1.000    1.000\n    s.n               0.010    0.009    1.108    0.268    1.000    1.000\n\nConstraints:\n                                               |Slack|\n    L1 - (3-L2-L3)                               0.000\n    L4 - (3-L5-L6)                               0.000\n    t1 - (0-t2-t3)                               0.000\n    tt1 - (0-tt2-tt3)                            0.000\n```\n:::\n:::\n\n\n## Bayesian multivariate models\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ndata <- \"https://raw.githubusercontent.com/josh-jackson/bayes/master/mlm.csv\"\nmlm <- read.csv(data) \nhead(mlm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  ID group time    CON CON_SAL CON_SMN7    DAN DAN_CON DAN_SAL DAN_SMN7   DMN6\n1  6    PD    4 0.1929  0.0708   0.0088 0.1619  0.1156  0.0739   0.0041 0.1775\n2  6    PD    5 0.1949  0.0862   0.0040 0.1677  0.1173  0.0812   0.0204 0.1512\n3  6    PD    6 0.1811  0.0916  -0.0037 0.2153  0.1636  0.1133   0.0155 0.1733\n4 29    PD    4 0.1594  0.0438  -0.0253 0.1749  0.0161  0.0621   0.0121 0.2145\n5 29    PD    5 0.0881  0.0446  -0.0288 0.1356  0.0377  0.0277   0.0444 0.1338\n6 34  CTRL    4 0.1372  0.0113  -0.0792 0.1659  0.0045 -0.0075   0.0432 0.1250\n  DMN6_CON DMN6_DAN DMN6_SAL DMN6_SMN7    SAL SAL_SMN7   SMN7 wave       date\n1  -0.1162  -0.1184  -0.1264   -0.0257 0.2097   0.0695 0.0352    1 2011-01-07\n2  -0.0709  -0.1177  -0.1214   -0.0342 0.2036   0.0453 0.0504    2 2011-12-19\n3  -0.0994  -0.1215  -0.1622   -0.0295 0.2024   0.0443 0.0135    3 2012-11-12\n4   0.0199  -0.1355  -0.0815   -0.0998 0.2337   0.0552 0.1104    1 2011-10-03\n5   0.0311  -0.0819  -0.0237   -0.0655 0.1229   0.0465 0.0761    2 2012-10-16\n6   0.0493  -0.0893  -0.0539   -0.0655 0.1432   0.0072 0.1226    1 2011-10-27\n  Exclude RSNdata RSNexclude RSNexcludeDevDem  CogDate_0 CCIRtrio_MR_date_0\n1    keep       1       keep             keep 2006-12-08               <NA>\n2    keep       1       keep             keep 2006-12-08               <NA>\n3    keep       1       keep             keep 2006-12-08               <NA>\n4    keep       1       keep          exclude 2007-11-27               <NA>\n5    keep       1       keep          exclude 2007-11-27               <NA>\n6    keep       1       keep             keep 2008-04-17               <NA>\n  Dur_PDsx_0 PIBpos18 Neuro_Dx NeuroCDR_0 NeuroCDR_1 NeuroCDR_2 NeuroCDR_3\n1         NA     PIB-      iPD   PD CDR=0  PD CDR=.5  PD CDR=.5   PD CDR=0\n2         NA     PIB-      iPD   PD CDR=0  PD CDR=.5  PD CDR=.5   PD CDR=0\n3         NA     PIB-      iPD   PD CDR=0  PD CDR=.5  PD CDR=.5   PD CDR=0\n4         NA     PIB-      iPD   PD CDR=0   PD CDR=0       <NA>  PD CDR=.5\n5         NA     PIB-      iPD   PD CDR=0   PD CDR=0       <NA>  PD CDR=.5\n6         NA     PIB-       HC   HC CDR=0       <NA>       <NA>       <NA>\n  NeuroCDR_4 NeuroCDR_5 NeuroCDR_6 NeuroCDR_7 NeuroCDR_8  YOB    Sex Ethnicity\n1  PD CDR=.5  PD CDR=.5  PD CDR=.5  PD CDR=.5 PD CDR=0.5 1937 female caucasian\n2  PD CDR=.5  PD CDR=.5  PD CDR=.5  PD CDR=.5 PD CDR=0.5 1937 female caucasian\n3  PD CDR=.5  PD CDR=.5  PD CDR=.5  PD CDR=.5 PD CDR=0.5 1937 female caucasian\n4  PD CDR=.5   PD CDR=1  PD CDR=.5       <NA>       <NA> 1935   male caucasian\n5  PD CDR=.5   PD CDR=1  PD CDR=.5       <NA>       <NA> 1935   male caucasian\n6   HC CDR=0       <NA>   HC CDR=0       <NA>       <NA> 1944 female caucasian\n  Education APOEs APOE4 Orig_MCBP_30to60    Asyn    Abeta Total_Tau      week\n1        14    33     0     -0.084801180      NA       NA        NA 0.0000000\n2        14    33     0     -0.084801180      NA       NA        NA 0.9479452\n3        14    33     0     -0.084801180      NA       NA        NA 1.8493151\n4        14    23     0      0.001760821 3356.47 1273.076   357.214 0.0000000\n5        14    23     0      0.001760821 3356.47 1273.076   357.214 1.0383562\n6        12    33     0      0.105326328      NA       NA        NA 0.0000000\n  Cog_rest_datediff\n1                NA\n2                NA\n3                NA\n4                NA\n5                NA\n6                NA\n```\n:::\n:::\n\n\n\n-----\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(brms)\nmlm.4 <- \n  brm(family = gaussian,\n      CON ~ 1 + time + (1 + time | ID),\n      prior = c(prior(normal(0, 1.5), class = Intercept),\n                prior(normal(0, 1.5), class = b),\n                prior(normal(0, 1.5), class = sd, coef = Intercept, group = ID), \n                prior(normal(0, 1.5), class = sd, coef = time, group = ID), \n                prior(exponential(1), class = sigma),\n                prior(lkj(2), class = cor)),\n      iter = 4000, warmup = 1000, chains = 4, cores = 4,\n      file = \"mlm.4\",\n      data = mlm)\nsummary(mlm.4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: CON ~ 1 + time + (1 + time | ID) \n   Data: mlm (Number of observations: 225) \n  Draws: 4 chains, each with iter = 4000; warmup = 1000; thin = 1;\n         total post-warmup draws = 12000\n\nGroup-Level Effects: \n~ID (Number of levels: 91) \n                    Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)           0.06      0.01     0.05     0.07 1.00     3080     3528\nsd(time)                0.00      0.00     0.00     0.01 1.00     1501     1367\ncor(Intercept,time)    -0.08      0.39    -0.75     0.72 1.00     8963     7456\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     0.19      0.01     0.18     0.21 1.00     5084     6825\ntime         -0.00      0.00    -0.01     0.00 1.00    10026     7880\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.05      0.00     0.04     0.05 1.00     4129     5352\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n:::\n\n\n\n\n\n-----\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nmv.1 <- \n  brm(family = gaussian,\n      mvbind(CON, DAN) ~ 1 + time + (1 + time | ID),\n      prior = c(prior(normal(0, 1.5), class = Intercept),\n                prior(normal(0, 1.5), class = b),\n                prior(lkj(2), class = cor),\n                prior(lkj(2), class = rescor)),\n      iter = 4000, warmup = 1000, chains = 4, cores = 4,\n      file = \"mv.1\",\n      data = mlm)\nsummary(mv.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: MV(gaussian, gaussian) \n  Links: mu = identity; sigma = identity\n         mu = identity; sigma = identity \nFormula: CON ~ 1 + time + (1 + time | ID) \n         DAN ~ 1 + time + (1 + time | ID) \n   Data: mlm (Number of observations: 225) \n  Draws: 4 chains, each with iter = 4000; warmup = 1000; thin = 1;\n         total post-warmup draws = 12000\n\nGroup-Level Effects: \n~ID (Number of levels: 91) \n                            Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(CON_Intercept)               0.06      0.01     0.05     0.07 1.00     3184\nsd(CON_time)                    0.00      0.00     0.00     0.01 1.02      309\nsd(DAN_Intercept)               0.04      0.01     0.03     0.05 1.00     2250\nsd(DAN_time)                    0.00      0.00     0.00     0.01 1.00      806\ncor(CON_Intercept,CON_time)    -0.14      0.39    -0.77     0.70 1.00     2604\ncor(DAN_Intercept,DAN_time)    -0.04      0.40    -0.75     0.76 1.00     4314\n                            Tail_ESS\nsd(CON_Intercept)               6838\nsd(CON_time)                      54\nsd(DAN_Intercept)               2293\nsd(DAN_time)                     953\ncor(CON_Intercept,CON_time)     4370\ncor(DAN_Intercept,DAN_time)     7145\n\nPopulation-Level Effects: \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nCON_Intercept     0.19      0.01     0.18     0.21 1.00     2974     3996\nDAN_Intercept     0.20      0.01     0.19     0.22 1.00     3085     6662\nCON_time         -0.00      0.00    -0.01     0.00 1.00     8481     9014\nDAN_time         -0.01      0.00    -0.01    -0.00 1.00     1963     2066\n\nFamily Specific Parameters: \n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma_CON     0.05      0.00     0.04     0.05 1.01      359       82\nsigma_DAN     0.05      0.00     0.04     0.06 1.00     1279     1194\n\nResidual Correlations: \n                Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nrescor(CON,DAN)     0.13      0.09    -0.05     0.32 1.01      418      160\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n:::\n\n\n\n------\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfixef(mv.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                  Estimate   Est.Error         Q2.5         Q97.5\nCON_Intercept  0.194589928 0.007834112  0.179361004  0.2097894777\nDAN_Intercept  0.203763593 0.006581122  0.190879710  0.2166098867\nCON_time      -0.002881418 0.002247423 -0.007293958  0.0016142091\nDAN_time      -0.005110302 0.002261724 -0.009492880 -0.0007040594\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidybayes)\nmv.1 %>% \n  spread_draws(rescor__CON__DAN) %>% \n   median_qi()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 6\n  rescor__CON__DAN  .lower .upper .width .point .interval\n             <dbl>   <dbl>  <dbl>  <dbl> <chr>  <chr>    \n1            0.125 -0.0536  0.317   0.95 median qi       \n```\n:::\n:::\n\n\n\n-------\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nmv.1 %>% \n  spread_draws(rescor__CON__DAN) %>% \n   ggplot(aes(x = rescor__CON__DAN)) +\n   stat_halfeye()\n```\n\n::: {.cell-output-display}\n![](multi-6_files/figure-revealjs/unnamed-chunk-10-1.png){width=960}\n:::\n:::\n\n\n\n--------\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nmlm.wide <- mlm %>% \n  dplyr::select(ID, DAN, CON, wave) %>% \n  pivot_longer(cols = DAN:CON, names_to = \"trait\", values_to = \"value\") %>% \n  pivot_wider(id_cols = \"ID\", names_from = c(\"trait\", \"wave\"), values_from = value)\n\nhead(mlm.wide)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 9\n     ID DAN_1 CON_1 DAN_2  CON_2  DAN_3  CON_3 DAN_4 CON_4\n  <int> <dbl> <dbl> <dbl>  <dbl>  <dbl>  <dbl> <dbl> <dbl>\n1     6 0.162 0.193 0.168 0.195   0.215  0.181    NA    NA\n2    29 0.175 0.159 0.136 0.0881 NA     NA        NA    NA\n3    34 0.166 0.137 0.140 0.0746 NA     NA        NA    NA\n4    36 0.152 0.139 0.205 0.180  NA     NA        NA    NA\n5    37 0.219 0.226 0.158 0.178   0.259  0.152    NA    NA\n6    48 0.130 0.250 0.270 0.232   0.248  0.173    NA    NA\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nbv.c <- '\n\n    i.dan =~ 1*DAN_1 + 1*DAN_2 + 1*DAN_3 + 1*DAN_4\n    s.dan =~ 0*DAN_1 + 1*DAN_2 + 2*DAN_3 + 3*DAN_4\n\n    i.con =~ 1*CON_1 + 1*CON_2 + 1*CON_3 + 1*CON_4\n    s.con =~ 0*CON_1 + 1*CON_2 + 2*CON_3 + 3*CON_4\n\n'\nfit.bv.c <- growth(bv.c, data = mlm.wide, missing = \"ML\")\nsummary(fit.bv.c,standardized=TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nlavaan 0.6-11 ended normally after 384 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        22\n                                                      \n  Number of observations                            91\n  Number of missing patterns                         3\n                                                      \nModel Test User Model:\n                                                      \n  Test statistic                                99.387\n  Degrees of freedom                                22\n  P-value (Chi-square)                           0.000\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Observed\n  Observed information based on                Hessian\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  i.dan =~                                                              \n    DAN_1             1.000                               0.049    0.790\n    DAN_2             1.000                               0.049    0.765\n    DAN_3             1.000                               0.049    0.767\n    DAN_4             1.000                               0.049    0.503\n  s.dan =~                                                              \n    DAN_1             0.000                               0.000    0.000\n    DAN_2             1.000                               0.029    0.450\n    DAN_3             2.000                               0.058    0.901\n    DAN_4             3.000                               0.087    0.886\n  i.con =~                                                              \n    CON_1             1.000                               0.053    0.734\n    CON_2             1.000                               0.053    0.725\n    CON_3             1.000                               0.053    0.710\n    CON_4             1.000                               0.053    0.566\n  s.con =~                                                              \n    CON_1             0.000                                  NA       NA\n    CON_2             1.000                                  NA       NA\n    CON_3             2.000                                  NA       NA\n    CON_4             3.000                                  NA       NA\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  i.dan ~~                                                              \n    s.dan            -0.001    0.000   -1.087    0.277   -0.362   -0.362\n    i.con             0.001    0.000    1.949    0.051    0.340    0.340\n    s.con             0.000    0.000    0.300    0.764    0.121    0.121\n  s.dan ~~                                                              \n    i.con             0.001    0.000    1.972    0.049    0.418    0.418\n    s.con            -0.000    0.000   -1.615    0.106   -0.701   -0.701\n  i.con ~~                                                              \n    s.con             0.000    0.000    0.603    0.546    0.409    0.409\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .DAN_1             0.000                               0.000    0.000\n   .DAN_2             0.000                               0.000    0.000\n   .DAN_3             0.000                               0.000    0.000\n   .DAN_4             0.000                               0.000    0.000\n   .CON_1             0.000                               0.000    0.000\n   .CON_2             0.000                               0.000    0.000\n   .CON_3             0.000                               0.000    0.000\n   .CON_4             0.000                               0.000    0.000\n    i.dan             0.202    0.006   31.530    0.000    4.100    4.100\n    s.dan            -0.009    0.005   -1.926    0.054   -0.318   -0.318\n    i.con             0.192    0.007   26.588    0.000    3.659    3.659\n    s.con            -0.004    0.004   -0.952    0.341       NA       NA\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .DAN_1             0.001    0.001    2.166    0.030    0.001    0.376\n   .DAN_2             0.002    0.000    4.723    0.000    0.002    0.461\n   .DAN_3             0.000    0.001    0.573    0.566    0.000    0.100\n   .DAN_4             0.003    0.002    1.282    0.200    0.003    0.284\n   .CON_1             0.002    0.001    3.214    0.001    0.002    0.461\n   .CON_2             0.002    0.001    4.062    0.000    0.002    0.398\n   .CON_3             0.002    0.001    2.649    0.008    0.002    0.417\n   .CON_4             0.006    0.003    1.674    0.094    0.006    0.669\n    i.dan             0.002    0.001    3.156    0.002    1.000    1.000\n    s.dan             0.001    0.000    2.253    0.024    1.000    1.000\n    i.con             0.003    0.001    3.187    0.001    1.000    1.000\n    s.con            -0.000    0.000   -0.586    0.558       NA       NA\n```\n:::\n:::\n\n\n\n## More complex SEM multivariate models \n\nSuggested readings:\n\nhttps://www.annualreviews.org/doi/abs/10.1146/annurev.psych.60.110707.163612\n\nhttps://www.sciencedirect.com/science/article/pii/S187892931730021X#sec0125\n\n\n## Two wave assessments\n\nHow to measure change, or should we? https://www.gwern.net/docs/dnb/1970-cronbach.pdf This paper lays out some of the problems that occur with standard treatments of two wave assessments. \n\nThe most basic two wave form of change is a difference score. However, many have said these are problematic. \nThe issues are: \n1. hard to separate measurement error from true change  \n2. unreliable estimate of change  \n3. initial level (or last level) may be driving change. How to account for? \n\n----\n\n- The alternative is a standard residual gain/change score where you regress time 2 onto time 1. This overcomes some of the issues raised about because we are being conservative about the error by \"regressing to the mean\" such that people with larger changes than average will have their change scores \"shrunken\" to the average, must like we do with MLMs. \n\n- This also helps with accounting for starting values that may be responsible for the changes, as this is literally controlling for the initial level. \n\n-----\n\nThe issues with residualized change models, however, are: \n\n1. it isn't true change, as you are implying people change similarly \n\n2. it does not account for unreliability of change in a principled way \n \n\n## Lords Paradox\n\nThis has lead to what is known as Lord's paradox. Take the two approaches above, simplified to: \n\n`lm(t2-t1 ~ group)`\n  \n`lm(t2 ~ t1 + group)`\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  id group          T1          T2          diff\n1  1    Tx -0.30176644 -0.07218389  0.2295825445\n2  2    Tx  0.06935731  0.09741980  0.0280624915\n3  3    Tx  0.27111029  0.12699551 -0.1441147849\n4  4    Tx -0.58642443 -0.16449642  0.4219280069\n5  5    Tx  0.10728117  0.07408057 -0.0332006005\n6  6    Tx  0.12651397  0.12665183  0.0001378524\n```\n:::\n:::\n\n\n\n## change score/gain score model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(lm(diff ~ group, df)) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = diff ~ group, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.5174 -0.1133  0.0208  0.1310  0.4612 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)  \n(Intercept)  0.038975   0.017300   2.253   0.0254 *\ngroupControl 0.004028   0.024466   0.165   0.8694  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.173 on 198 degrees of freedom\nMultiple R-squared:  0.0001369,\tAdjusted R-squared:  -0.004913 \nF-statistic: 0.02711 on 1 and 198 DF,  p-value: 0.8694\n```\n:::\n:::\n\n\n## residualized change score model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(lm(T2 ~ group + T1, df))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = T2 ~ group + T1, data = df)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.315819 -0.066341  0.005835  0.060977  0.268154 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   0.01724    0.01008    1.71   0.0888 .  \ngroupControl  0.44744    0.02648   16.90   <2e-16 ***\nT1            0.44538    0.02797   15.92   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1002 on 197 degrees of freedom\nMultiple R-squared:  0.9463,\tAdjusted R-squared:  0.9457 \nF-statistic:  1734 on 2 and 197 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n------\n\nWhat is going on? We are asking different questions by not accounting for T1 in the former model. The change score model is accounting for the total effect (in mediation language) whereas the residualized change score model is only interested in the direct effect. \n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nmod <- '\n  T1 ~ a*group\n  T2 ~ b*group + c*T1\n  \n  # total effect\n  TE := (a*-1) + (a*c*1) + (b*1)  \n'\nlord <- sem(mod, data=df)\nsummary(lord)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nlavaan 0.6-11 ended normally after 1 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         5\n                                                      \n  Number of observations                           200\n                                                      \nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  T1 ~                                                \n    group      (a)    0.800    0.036   22.317    0.000\n  T2 ~                                                \n    group      (b)    0.447    0.026   17.028    0.000\n    T1         (c)    0.445    0.028   16.043    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .T1                0.064    0.006   10.000    0.000\n   .T2                0.010    0.001   10.000    0.000\n\nDefined Parameters:\n                   Estimate  Std.Err  z-value  P(>|z|)\n    TE                0.004    0.024    0.165    0.869\n```\n:::\n:::\n\n\n\n------\n\nWhat is not immediately obvious is that the change score can be conceptualized as a series of regressions. Starting with the residualized change score model\n\n`T2 = b*T1 + e`\n\nIf we assume that the relationship (b) between T1 and T2 is 1. We can re-write as:\n\n`T2 = 1*T1 + e`\n\nThen we can subtract T1 fro each side of the model, leaving: \n\n`T2 - T1 = e`\n\nIn other words, a change score is equivalent to assuming a perfect regression association (correlation) between timepoints. \n\n------\n\nHere, the residual will be equal to the average change and the variance of that will be the variance in the change. This can be thought of as akin to the mean and variance of our latent slope variable.\n\nLets visualize each of these models via path models\n\n\n## Residualized change model\n\n![](res.change.png)\n\n\n\n\nOur latent residual can be conceptualized as what is left over from T2 after accounting for T1 (based on the average association between T1 and T2). We now have a measure of error/change that is not correlated to T1. \n\n\n------\n\n\n::: {.cell}\n\n```{.r .cell-code}\nres.change <- '\n  T2 ~ T1\n'\nres.change <- sem(res.change, data=df)\nsummary(res.change)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nlavaan 0.6-11 ended normally after 1 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         2\n                                                      \n  Number of observations                           200\n                                                      \nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  T2 ~                                                \n    T1                0.845    0.023   36.317    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .T2                0.024    0.002   10.000    0.000\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(lm(T2~T1, df))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = T2 ~ T1, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.46327 -0.10765  0.00553  0.11529  0.44807 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  0.09699    0.01391   6.974 4.51e-11 ***\nT1           0.84469    0.02338  36.135  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1565 on 198 degrees of freedom\nMultiple R-squared:  0.8683,\tAdjusted R-squared:  0.8677 \nF-statistic:  1306 on 1 and 198 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n\n--------\n\n\n::: {.cell}\n\n```{.r .cell-code}\nres.change.m <- '\n  T2 ~ T1\n'\nres.change.m <- sem(res.change.m, data=df,meanstructure = TRUE)\nsummary(res.change.m)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nlavaan 0.6-11 ended normally after 27 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         3\n                                                      \n  Number of observations                           200\n                                                      \nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  T2 ~                                                \n    T1                0.845    0.023   36.317    0.000\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .T2                0.097    0.014    7.009    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .T2                0.024    0.002   10.000    0.000\n```\n:::\n:::\n\n\n## residual sd from the regression output is equal to the SEM variance\n\n::: {.cell}\n\n```{.r .cell-code}\n0.1565^2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.02449225\n```\n:::\n:::\n\n\nNote that this isn't telling us anything about the difference score or even the means of the numbers per se. \n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(psych)\ndescribe(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       vars   n   mean    sd median trimmed   mad   min    max  range  skew\nid*       1 200 100.50 57.88 100.50  100.50 74.13  1.00 200.00 199.00  0.00\ngroup*    2 200   1.50  0.50   1.50    1.50  0.74  1.00   2.00   1.00  0.00\nT1        3 200   0.36  0.47   0.41    0.35  0.61 -0.59   1.51   2.10  0.06\nT2        4 200   0.40  0.43   0.35    0.40  0.61 -0.54   1.17   1.71  0.01\ndiff      5 200   0.04  0.17   0.06    0.05  0.17 -0.47   0.50   0.98 -0.44\n       kurtosis   se\nid*       -1.22 4.09\ngroup*    -2.01 0.04\nT1        -1.16 0.03\nT2        -1.59 0.03\ndiff      -0.05 0.01\n```\n:::\n:::\n\n\nThis is why I am not a fan of the residualzed change score. It doesn't get at change the way we typically think of it. Previously our MLMs provide a way to think about what change means, and SEMs will do the same.  \n\n##  Latent change score\nLooping back to concerns about difference scores and residualized change scores, we can address these using SEM. The problems raised above \n\n- It isn't true change, as you are implying people change similarly\n- Change is likely associated with T1\n- Hard to separate measurement error from true change\n\ngo away when: \n\n1) Examine absolute differences   \n2) Able to separate (account for) initial levels from change.   \n3) Measuring change latently, and thus error free.\n\nNumber 2 is accomplished above in the residualized change models. However, what is not accomplished is getting terms similar to the slope component of a growth curve ie absolute change. Nor does it account for measurement error\n\n## Lets compare this with our old trusty mlm friend\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ndf.long <- df %>% \n  pivot_longer(cols=T1:T2, names_to = c(\"drop\",\"time\"),names_pattern = \"([A-Za-z]+)(\\\\d+)\", values_to = \"value\") %>% \n  select(-drop) %>% \n  mutate(time = as.numeric(time)) %>% \n  mutate(time = time -1)\nhead(df.long)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 5\n  id    group    diff  time   value\n  <fct> <fct>   <dbl> <dbl>   <dbl>\n1 1     Tx     0.230      0 -0.302 \n2 1     Tx     0.230      1 -0.0722\n3 2     Tx     0.0281     0  0.0694\n4 2     Tx     0.0281     1  0.0974\n5 3     Tx    -0.144      0  0.271 \n6 3     Tx    -0.144      1  0.127 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(lme4)\nmlm.1 <- lmer(value ~  time + (1  | id ), data = df.long)\nsummary(mlm.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: value ~ time + (1 | id)\n   Data: df.long\n\nREML criterion at convergence: 118.1\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-1.99283 -0.47843 -0.02817  0.51432  2.38752 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 0.19014  0.436   \n Residual             0.01489  0.122   \nNumber of obs: 400, groups:  id, 200\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  0.36056    0.03202  11.261\ntime         0.04099    0.01220   3.359\n\nCorrelation of Fixed Effects:\n     (Intr)\ntime -0.191\n```\n:::\n:::\n\n\n--------\n\nTime equals the absolute difference!! Intercept is the value at T1. I can recreate the mean values with this output. And I can see how people differ at T1. \n\nHowever, this does not tell you differences in how people change. That is, everyone is assumed to change similarly ie fixed slope. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4)\nmlm.2 <- lmer(value ~  time + (1 + time  | id ), data = df.long)\n```\n:::\n\noutput: \nError: number of observations (=400) <= number of random effects (=400) for term (1 + time | id); the random-effects parameters and the residual variance (or scale parameter) are probably unidentifiable\n\n<sad trombone noise>\n\n-------\n\nWe can either do two things: go with Bayes or go with SEM. SEM is actully more flexible here so lets explore this option. \n\nKnowing what we know about recreating difference scores via constraints, we can also make a latent change score by modifying the same residual path model. This time assuming the association between t1 and t2 are the same. \n\n----\n\n\n![](latent.change.png)\n\n\nNow we can interpret the residual as change, as it is explicitly what is left over from T2 after accoutering for T1. This is starting to look like what we for a growth model. \n\n-----\n\nWe have: \n1. Mean and variance of the slope(change), akin to our random and fixed effects in MLM\n2. Covariance between intercept and slope. \n\nTo test whether or not our slope is significant we can compare that with a model where slope is constrained to be zero. Same for testing the slope variance. \n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nlatent.change <- '\n  #define difference score\n  T2 ~ 1*T1\n  \n  # define the latent change variable\n  change =~ 1*T2\n  \n  #estimate means\n  change ~ 1\n  T1 ~ 1\n  \n  #Constrains mean of T2 to 0\n  T2 ~0*1\n\n  #estimate variance of change\n  change ~~ change\n\n  #estimate variance of T1 intercept\n  T1 ~~ T1\n  \n  #constrain variance of T2 to 0\n  T2 ~~ 0*T2\n\n  #intercept slope covariance\n  change ~~ T1\n'\n\nlatent.change <- sem(latent.change, data=df)\nsummary(latent.change)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nlavaan 0.6-11 ended normally after 18 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         5\n                                                      \n  Number of observations                           200\n                                                      \nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  change =~                                           \n    T2                1.000                           \n\nRegressions:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  T2 ~                                                \n    T1                1.000                           \n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  change ~~                                           \n    T1               -0.035    0.006   -5.553    0.000\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)\n    change            0.041    0.012    3.367    0.001\n    T1                0.361    0.033   10.774    0.000\n   .T2                0.000                           \n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n    change            0.030    0.003   10.000    0.000\n    T1                0.224    0.022   10.000    0.000\n   .T2                0.000                           \n```\n:::\n:::\n\n\n\n-----\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndescribe(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       vars   n   mean    sd median trimmed   mad   min    max  range  skew\nid*       1 200 100.50 57.88 100.50  100.50 74.13  1.00 200.00 199.00  0.00\ngroup*    2 200   1.50  0.50   1.50    1.50  0.74  1.00   2.00   1.00  0.00\nT1        3 200   0.36  0.47   0.41    0.35  0.61 -0.59   1.51   2.10  0.06\nT2        4 200   0.40  0.43   0.35    0.40  0.61 -0.54   1.17   1.71  0.01\ndiff      5 200   0.04  0.17   0.06    0.05  0.17 -0.47   0.50   0.98 -0.44\n       kurtosis   se\nid*       -1.22 4.09\ngroup*    -2.01 0.04\nT1        -1.16 0.03\nT2        -1.59 0.03\ndiff      -0.05 0.01\n```\n:::\n:::\n\n\nChange now has an intercept and a variance -- just like in growth curves! \n\n\n## Residualized latent change score\n\nNote that we haven't yet removed the variance from the T1 (control for T1). There is a negative assocaition between where people start and how much they change. \n\nThis may or may not be something you want to do. It is mostly helpful if change has occurred prior to T1 and you are looking at the impact of some variable on change. If you are doing an intervention that takes place after T1 then maybe stick to latent change model. If you are measuring a developmental process across time and want to make sure that initial levels aren't influencing change then you may want to do this. If you are doing that but think that initial levels are related to the change process then maybe you would be over controlling, wiping away what may be important. ¯\\_(ツ)_/¯\n\n\n![](res.lat.change.png)\n\n",
    "supporting": [
      "multi-6_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    function fireSlideChanged(previousSlide, currentSlide) {\n\n      // dispatch for htmlwidgets\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for reveal\n    if (window.Reveal) {\n      window.Reveal.addEventListener(\"slidechanged\", function(event) {\n        fireSlideChanged(event.previousSlide, event.currentSlide);\n      });\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}