---
title: "bends"
execute: 
  echo: true
format: revealjs
editor: visual
---

## Trajectories that bend

```{r, echo = FALSE}
library(tidyverse)
library(lavaan)
library(modelr)
library(lme4)
```


- Thus far we have been sticking with monotonically increasing trajectories. This is a good assumption given the amount of data often found, along with the simplicity. 

- Often we want to see if trajectories are not straight. Development is not simple so our lines should not be. 

- Need effective strategies for line that bend that also balance tradeoffs with interprettability and overfitting


## Polynomial and Splines

Polynomials (quadratic)
level 1: 
$${Y}_{ij} = \beta_{0j}  + \beta_{1j}(Time_{ij} - \bar{X)} + \beta_{2j}(Time_{ij} - \bar{X)}^2 + \varepsilon_{ij}$$


Level 2: 
$${\beta}_{0j} = \gamma_{00} +   U_{0j}$$  
$${\beta}_{1j} = \gamma_{10} +  U_{1j}$$ 
$${\beta}_{2j} = \gamma_{20} +  U_{2j}$$ 



## MLM poly example


```{r}
#| code-fold: true
personality <- read.csv("https://raw.githubusercontent.com/josh-jackson/longitudinal-2022/main/Subject_personality.csv")

ggplot(personality,
   aes(x = neodate, y = neuroticism, group = mapid)) + geom_line()  

```


---

```{r}
#| code-fold: true
personality<- personality %>% 
  group_by(mapid) %>%
  arrange(neodate) %>% 
  dplyr::mutate(wave = seq_len(n())) 
```

```{r}
#| code-fold: true
ggplot(personality,
   aes(x = wave, y = neuroticism, group = mapid)) + geom_line()  

```

---

```{r}
#| code-fold: true
personality$neodate <- as.Date(personality$neodate, origin = "1900-01-01")

ggplot(personality,
   aes(x = neodate, y = neuroticism, group = mapid)) + geom_line()  


```


-----


```{r, echo = FALSE}
#| code-fold: true
# yes this code could be done more efficiently
personality.wide <- personality %>% 
  dplyr::select(mapid, wave, neodate) %>% 
  spread(wave, neodate) 

personality.wide$wave_1 <- personality.wide$'1'
personality.wide$wave_2 <- personality.wide$'2'
personality.wide$wave_3 <- personality.wide$'3'
personality.wide$wave_4 <- personality.wide$'4'
personality.wide$wave_5 <- personality.wide$'5'

personality.wide <- personality.wide %>% 
mutate (w_1 = (wave_1 - wave_1)/365,
          w_2 = (wave_2 - wave_1)/365,
          w_3 = (wave_3 - wave_1)/365,
          w_4 = (wave_4 - wave_1)/365,
        w_5 = (wave_5 - wave_1)/365)

personality.long <- personality.wide %>% 
  dplyr::select(mapid, w_1:w_5) %>% 
  gather(wave, year, -mapid) %>% 
  separate(wave, c('weeks', 'wave' ), sep="_") %>% 
 dplyr::select(-weeks) 

personality.long$wave <-  as.numeric(personality.long$wave)


personality <- personality %>% 
   left_join(personality.long, by = c('mapid', 'wave' )) 

personality.s <- personality %>% 
  group_by(mapid) %>% 
  tally() %>% 
   filter(n >=2) 

 personality <- personality %>% 
   filter(mapid %in% personality.s$mapid)

personality <- personality %>% 
  select(-neodate)
 
personality
```


---

```{r}

p1 <- lmer(extraversion ~ year + (year | mapid), data=personality)
summary(p1)
```

---

quadratic 
```{r, eval = FALSE}
p2 <- lmer(extraversion ~ year + I(year^2) + (1 + year  | mapid), data=personality)
```
I() wont work on difftime objects. Booo

------

quadratic 
```{r}

personality <- personality %>% 
  mutate(year = as.numeric(year))

p2 <- lmer(extraversion ~ year + I(year^2) + (1 + year | mapid), data=personality)
```



-------

```{r}
summary(p2)
```


------

#### The importance of centering  

- This is an interaction model, where you have a level 1 interaction. As such, centering is important to correctly interpret parameters.  

------

```{r}
personality <- personality %>% 
  mutate(year.c = year - 3.10)

p3 <- lmer(extraversion ~ year.c + I(year.c^2) + (1 + year.c | mapid), data=personality)
```


----

```{r}
summary(p3)
```


-------

graphically, what does this look like? 

```{r}
#| code-fold: true
personality %>% 
  data_grid(year.c = seq(-3.1,10, 1), .model = personality) %>% 
  add_predictions(p3) %>% 
   group_by(year.c) %>% 
  dplyr::summarize(pred = mean(pred)) %>% 
  ggplot(aes(x = year.c, y = pred)) +
  geom_line()

```

-------

non-centered model
```{r}
#| code-fold: true
personality %>% 
  data_grid(year = seq(0,13, 1), .model = personality) %>% 
  add_predictions(p2) %>% 
   group_by(year) %>% 
  dplyr::summarize(pred = mean(pred)) %>% 
  ggplot(aes(x = year, y = pred)) +
  geom_line()

```



-----

```{r}
#| code-fold: true
personality %>% 
  data_grid(year.c = seq(-4,10, 1), .model = personality) %>% 
  add_predictions(p3) %>% 
  ggplot(aes(x = year.c, y = pred, group = mapid)) +
  geom_line(alpha = .15)

```


-------

compare with a linear model

```{r}
anova(p3, p1)
```


## SEM poly example

```{r}
#| code-fold: true

#use alcohol data from before
alcohol <- read.csv("https://raw.githubusercontent.com/josh-jackson/longitudinal-2022/main/alcohol1_pp.csv")

alcohol.wide <- alcohol %>% 
  dplyr::select(-X, -age_14, -ccoa) %>% 
  pivot_wider(names_from = "age", 
              names_prefix = "alcuse_",
              values_from  = alcuse) 
alcohol.wide
```


-------

```{r}
#| code-fold: true

model.4 <- '  

i =~ 1*alcuse_14 + 1*alcuse_15 + 1*alcuse_16 
s =~ 0*alcuse_14 + 2*alcuse_15 + 4*alcuse_16
q =~ 0*alcuse_14 + 4*alcuse_15 + 16*alcuse_16  

q~~0*q

alcuse_14~~a*alcuse_14
alcuse_15~~a*alcuse_15
alcuse_16~~a*alcuse_16
'

p4 <- growth(model.4, data = alcohol.wide, missing = "ML")

```

---

```{r}
summary(p4)
```

-----

Lets use the personality data from the mlm above. First gotta convert into wide. 
```{r}
#| code-fold: true
personality2 <- read.csv("https://raw.githubusercontent.com/josh-jackson/longitudinal-2022/main/Subject_personality.csv")

p.wide<- personality2 %>% 
  group_by(mapid) %>%
  arrange(neodate) %>% 
  dplyr::mutate(wave = seq_len(n())) %>% 
  select(-c(age:neuroticism), -c(openness:gender)) %>% 
  pivot_wider(names_from = "wave", values_from = "extraversion",names_prefix = "extra_")

p.wide
```


------

```{r}

model.5 <- '  

i =~ 1*extra_1 + 1*extra_2 + 1*extra_3 + 1*extra_4 + 1*extra_5 
s =~ 0*extra_1 + 1*extra_2 + 2*extra_3 + 3*extra_4 + 4*extra_5 
q =~ 0*extra_1 + 1*extra_2 + 4*extra_3 + 9*extra_4 + 16*extra_5  

'

p5 <- growth(model.5, data = p.wide, missing = "ML")

```

----

```{r}
summary(p5, fit.measures = TRUE, standardize = TRUE)
```



-------

constrain variances
```{r}

model.6 <- '  

i =~ 1*extra_1 + 1*extra_2 + 1*extra_3 + 1*extra_4 + 1*extra_5 
s =~ 0*extra_1 + 1*extra_2 + 2*extra_3 + 3*extra_4 + 4*extra_5 
q =~ 0*extra_1 + 1*extra_2 + 4*extra_3 + 9*extra_4 + 16*extra_5  

extra_1 ~~ Q*extra_1
extra_2 ~~ Q*extra_2
extra_3 ~~ Q*extra_3
extra_4 ~~ Q*extra_4
extra_5 ~~ Q*extra_5
'

p6 <- growth(model.6, data = p.wide, missing = "ML")

```

----

```{r}
summary(p6, fit.measures = TRUE, standardize = TRUE)
```



-----

```{r}
head(lavPredict(p6,type="lv"))
```



------

```{r}
head(lavPredict(p6,type="ov"))
```


-------------


```{r}
#| code-fold: true
as_tibble(lavPredict(p6,type="ov")) %>% 
  rowid_to_column("ID") %>% 
  pivot_longer(cols = starts_with("extra"), names_to = c(".value", "wave"), names_sep = "_") %>%
dplyr::mutate(wave = as.numeric(wave)) %>% 
ggplot(aes(x = wave, y = extra, group = ID, color = factor(ID))) +
  geom_line(alpha = .2) +  theme(legend.position = "none") 
```




## SEM latent basis

```{r}

#| code-fold: true
model.7 <- '  

i =~ 1*extra_1 + 1*extra_2 + 1*extra_3 + 1*extra_4 + 1*extra_5 
s =~ 0*extra_1 + extra_2 + extra_3 + extra_4 + 4*extra_5 

'

p7 <- growth(model.7, data = p.wide, missing = "ML")

```


-----

```{r}
summary(p7, fit.measures = TRUE, standardize = TRUE)
```



---------


```{r}
#| code-fold: true
as_tibble(lavPredict(p7,type="ov")) %>% 
  rowid_to_column("ID") %>% 
  pivot_longer(cols = starts_with("extra"), names_to = c(".value", "wave"), names_sep = "_") %>%
dplyr::mutate(wave = as.numeric(wave)) %>% 
ggplot(aes(x = wave, y = extra, group = ID, color = factor(ID))) +
  geom_line(alpha = .2) +  theme(legend.position = "none") 
```



--------

## Piecewise

- Fit more than 1 trajectory

- Best to use when we have a reason for a qualitative difference at a time point. For example, before your health event you may have a different trajectory than after

- Time modeled as dummy variables that represent different segments

- The point of separation is called a knot. You can have as many as you want and these can be pre-specified or let the data specify   

------

#### two-rate specification 
- The easiest example is to take your time variable and transform it into a Time1 and time2, that represent the different time periods 


```{r}
t1 <- tribble(
  ~time, ~t0, ~t1,~t2,~t3,~t4,~t5,
  "time 1", 0, 1,2,2,2,2,
  "time 2", 0, 0,0,1,2,3
)
t1
```


- Once you hit the knot your value stays the same. For the second curve, until you get to knot you don't have a trajectory. 

------

#### incremental curves

- Here the first trajectory keeps going, whereas the second trajectory starts at the position of the knot. 

```{r}
t2 <- tribble(
  ~time, ~t0, ~t1,~t2,~t3,~t4,~t5,
  "time 1", 0, 1,2,3,4,5,
  "time 2", 0, 0,0,1,2,3
)
t2
```


---

- The two coding schemes propose the same type of trajectory, the difference is in interpretation. 
- In the first, the two slope coefficients represent the actual slope in the respective time period. 
- In the second, the coefficient for time 2 represents the deviation from the slope in period 1. 




## mlm example

level 1: 

$${Y}_{ij} = \beta_{0j}  + \beta_{1j}Time1_{ij} + \beta_{2j}Time2_{ij} + \varepsilon_{ij}$$


Level 2: 
$${\beta}_{0j} = \gamma_{00} +  U_{0j}$$  

$${\beta}_{1j} = \gamma_{10} +  U_{1j}$$ 
$${\beta}_{2j} = \gamma_{20} +  U_{2j}$$ 


---

0 1 2 2 2    
0 0 0 1 2

```{r}

personality$time1 <- dplyr::recode(personality$wave, '1' = 0 , '2' = 1,  '3' = 2, '4' = 2,'5' = 2)      
personality$time2 <- recode(personality$wave, '1' = 0 , '2' = 0,  '3' = 0, '4' = 1,'5' = 2) 


```


---

```{r}
p7 <- lmer(extraversion ~ time1 + time2 + (time2 | mapid) , data=personality)
summary(p7)
```


------

0 1 3 4 5   (Wave)  
0 0 0 1 2  (same as time 2 previously)


```{r}
p8 <- lmer(extraversion ~ wave + time2 + (time2  | mapid) , data=personality)
summary(p8)
```


## SEM example


0 1 2 2 2   
0 0 0 1 2

```{r}
two.rate <- 'i =~ 1*extra_1 + 1*extra_2 + 1*extra_3 + 1*extra_4 + 1*extra_5 
s1 =~ 0*extra_1 + 1*extra_2 + 2*extra_3 + 2*extra_4 + 2*extra_5 
s2 =~ 0*extra_1 + 0*extra_2 + 0*extra_3 + 1*extra_4 + 2*extra_5  
'

p8 <- growth(two.rate, data = p.wide, missing = "ML")


```


-------

```{r}
summary(p8, fit.measures = TRUE, standardize = TRUE)
```




--------

0 1 2 3 4   
0 0 0 1 2  

```{r}
incremental <- 'i =~ 1*extra_1 + 1*extra_2 + 1*extra_3 + 1*extra_4 + 1*extra_5 
s1 =~ 0*extra_1 + 1*extra_2 + 2*extra_3 + 3*extra_4 + 4*extra_5 
s2 =~ 0*extra_1 + 0*extra_2 + 0*extra_3 + 1*extra_4 + 2*extra_5  
'

p9 <- growth(incremental, data = p.wide, missing = "ML")


```

------

```{r}
summary(p9, fit.measures = TRUE, standardize = TRUE)
```


-----


```{r}
#| code-fold: true
as_tibble(lavPredict(p9,type="ov")) %>% 
  rowid_to_column("ID") %>% 
  pivot_longer(cols = starts_with("extra"), names_to = c(".value", "wave"), names_sep = "_") %>%
dplyr::mutate(wave = as.numeric(wave)) %>% 
ggplot(aes(x = wave, y = extra, group = ID, color = factor(ID))) +
  geom_line(alpha = .2) +  theme(legend.position = "none") 

```


-----

different model, same figure? 
```{r}
#| code-fold: true
as_tibble(lavPredict(p8,type="ov")) %>% 
  rowid_to_column("ID") %>% 
  pivot_longer(cols = starts_with("extra"), names_to = c(".value", "wave"), names_sep = "_") %>%
dplyr::mutate(wave = as.numeric(wave)) %>% 
ggplot(aes(x = wave, y = extra, group = ID, color = factor(ID))) +
  geom_line(alpha = .2) +  theme(legend.position = "none") 

```



------

## splines + polynomial = polynomial piecewise


$${Y}_{ij} = \beta_{0j}  + \beta_{1j}Time1_{ij} +  \beta_{2j}Time1_{ij}^2 + \beta_{3j}Time2_{ij} + \varepsilon_{ij}$$

Level 2: 
$${\beta}_{0j} = \gamma_{00} +  U_{0j}$$  

$${\beta}_{1j} = \gamma_{10} +  U_{1j}$$ 
$${\beta}_{2j} = \gamma_{20} +  U_{2j}$$
$${\beta}_{3j} = \gamma_{30} +  U_{3j}$$ 






------

you really should have more waves per piece to model piecewise polynomial, but hey lets try it: 

```{r}
#| code-fold: true
two.rate.poly <- 'i =~ 1*extra_1 + 1*extra_2 + 1*extra_3 + 1*extra_4 + 1*extra_5 
s1 =~ -2*extra_1 + -1*extra_2 + 0*extra_3 + 0*extra_4 + 0*extra_5 
s2 =~ 0*extra_1 + 0*extra_2 + 0*extra_3 + 1*extra_4 + 2*extra_5  
s2poly =~ 0*extra_1 + 0*extra_2 + 0*extra_3 + 1*extra_4 + 4*extra_5 

extra_1 ~~ Q*extra_1
extra_2 ~~ Q*extra_2
extra_3 ~~ Q*extra_3
extra_4 ~~ Q*extra_4
extra_5 ~~ Q*extra_5

s2poly~~0*s2poly

'

p9 <- growth(two.rate.poly, data = p.wide, missing = "ML")


```


```{r}
summary(p9)
```


------

```{r}
#| code-fold: true
as_tibble(lavPredict(p9,type="ov")) %>% 
  rowid_to_column("ID") %>% 
  pivot_longer(cols = starts_with("extra"), names_to = c(".value", "wave"), names_sep = "_") %>%
dplyr::mutate(wave = as.numeric(wave)) %>% 
ggplot(aes(x = wave, y = extra, group = ID, color = factor(ID))) +
  geom_line(alpha = .2) +  theme(legend.position = "none") 

```


## GAMs

- standard longitudinal models are simple to understand (lines!), but fail to 

GAMs offer a middle ground: they can be fit to complex, nonlinear relationships and make good predictions in these cases, but we are still able to do inferential statistics and understand and explain the underlying structure of our models and why they make predictions that they do

